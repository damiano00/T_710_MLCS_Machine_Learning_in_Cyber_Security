{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d9cee6fd60c2a930",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:05.052638500Z",
     "start_time": "2023-09-16T00:09:05.052638500Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Damiano Pasquini\n",
    "email: damiano23@ru.is\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "path = \"./MachineLearningCVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(data_frame):\n",
    "    # Preprocess the columns\n",
    "    # TODO: infinite values and NaN values are meaningful so they must be handled differently and not dropped\n",
    "    data_frame.rename(columns=lambda x: x.strip(), inplace=True)  # Remove leading/trailing spaces from column names\n",
    "    data_frame[\"Label\"] = data_frame[\"Label\"].apply(lambda x: x.strip())\n",
    "    # change all values of Label column to either \"DoS\", \"Scan\", \"Benign\", or \"Exploit\"\n",
    "    #TODO: fix this\n",
    "    data_frame.replace([np.inf, -np.inf], np.nan, inplace=True) # Replace inf values with NaN\n",
    "    data_frame.dropna(inplace=True) # Drop rows with NaN values\n",
    "    data_frame[\"Label\"] = data_frame[\"Label\"].apply(preprocess_label_column()) #TODO: add label\n",
    "    return data_frame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:05.064495800Z",
     "start_time": "2023-09-16T00:09:05.059469200Z"
    }
   },
   "id": "188e9c38476a3557"
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "def preprocess_label_column(label):\n",
    "    # transform the content of the column \"Label\". If the value is \"BENIGN\" then it is changed to \"Benign\", if it contains \"DoS\" then it is changed to \"DoS\", if it contains \"PortScan\" then it is changed to \"Scan\", otherwise it is changed to \"Exploit\"\n",
    "    if \"BENIGN\" in label:\n",
    "        return \"Benign\"\n",
    "    elif \"DoS\" in label:\n",
    "        return \"DoS\"\n",
    "    elif \"PortScan\" in label:\n",
    "        return \"Scan\"\n",
    "    else:\n",
    "        return \"Exploit\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:05.064495800Z",
     "start_time": "2023-09-16T00:09:05.059469200Z"
    }
   },
   "id": "aab6f1aa53a7de92"
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "\n",
    "def merge_csv_files(path_to_csv_files, index=True, write_to_file=False):\n",
    "    csv_files = [f for f in os.listdir(path_to_csv_files) if f.endswith('.csv')]\n",
    "    dfs = [pd.read_csv(os.path.join(path_to_csv_files, f)) for f in csv_files]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    if write_to_file:\n",
    "        df.to_csv(\"./combined.csv\", index=index)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:05.070117600Z",
     "start_time": "2023-09-16T00:09:05.064495800Z"
    }
   },
   "id": "d533d0c26d8674f3"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "\n",
    "def train_test_by_days(path_to_files, df):\n",
    "    d_train = pd.DataFrame()\n",
    "    d_test = pd.DataFrame()\n",
    "    for file in os.listdir(path_to_files):\n",
    "        if file.endswith(\".csv\"):\n",
    "            first_word = file.split()[0].strip()\n",
    "            if first_word in [\"Monday\", \"Tuesday\", \"Wednesday\"]:\n",
    "                d_train = pd.concat([d_train, df])\n",
    "            elif first_word in [\"Thursday\", \"Friday\"]:\n",
    "                d_test = pd.concat([d_test, df])\n",
    "    return d_train, d_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:05.090732900Z",
     "start_time": "2023-09-16T00:09:05.076112400Z"
    }
   },
   "id": "d35a5286f90168bf"
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset(path_to_files, splitmode=None):\n",
    "    \"\"\"\n",
    "    Function to obtain the train dataset and the test dataset given the path where the csv files are,\n",
    "    and the percentage of training dataset\n",
    "    :param path_to_files: directory where the csv files are located \n",
    "    :param splitmode: number between 0 and 1, if specified indicates the percentage of the train set (d_train)  \n",
    "    :return: d_train and d_test, relatively training dataset and testing dataset\n",
    "    \"\"\"\n",
    "    # Ensure splitmode is within the valid range\n",
    "    if splitmode is not None and (splitmode < 0 or splitmode > 1):\n",
    "        raise ValueError(\"splitmode should be between 0 and 1\")\n",
    "    \n",
    "    df = merge_csv_files(path_to_files)\n",
    "    d_train = pd.DataFrame()\n",
    "    d_test = pd.DataFrame()\n",
    "    # Preprocess the columns of the combined dataframe\n",
    "    preprocess_data(df)\n",
    "    if splitmode is not None:\n",
    "        df = sklearn.utils.shuffle(df) # Shuffle the rows\n",
    "        # Split the processed data into two distinct Pandas data frames: one for the training set and one for the testing set.\n",
    "        split_index = int(len(df) * splitmode)\n",
    "        d_train = pd.concat([d_train, df[:split_index]])\n",
    "        d_test = pd.concat([d_test, df[split_index:]])\n",
    "    else:\n",
    "        # TODO: not working: error -> KeyError: 'Label'\n",
    "        d_train, d_test = train_test_by_days(path_to_files, df)\n",
    "    return d_train, d_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:05.090732900Z",
     "start_time": "2023-09-16T00:09:05.076112400Z"
    }
   },
   "id": "408c64b667aca2fd"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "def split_x_y(data):\n",
    "    \"\"\"\n",
    "    Split the dataset in data and labels (relatively X and y)\n",
    "    :param data: dataset\n",
    "    :return: tuple X and y, relatively data and labels for the given dataset\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=[\"Label\"])\n",
    "    y = data[\"Label\"] # TODO: not working: error -> KeyError: 'Label' when running with splitmode\n",
    "    return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:05.090732900Z",
     "start_time": "2023-09-16T00:09:05.088202800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train and test sets...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Benign' is not a valid function for 'Series' object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[141], line 7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mUsing scikit-learn, train a decision tree classifier on the training set.\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mTest the model firs with splitmode = 0.6 and then without splitmode.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating train and test sets...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m train_data, test_data \u001B[38;5;241m=\u001B[39m \u001B[43mget_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplitmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.6\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m train_data\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_data.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m test_data\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_data.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[139], line 17\u001B[0m, in \u001B[0;36mget_dataset\u001B[1;34m(path_to_files, splitmode)\u001B[0m\n\u001B[0;32m     15\u001B[0m d_test \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Preprocess the columns of the combined dataframe\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[43mpreprocess_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m splitmode \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m     df \u001B[38;5;241m=\u001B[39m sklearn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mshuffle(df) \u001B[38;5;66;03m# Shuffle the rows\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[135], line 10\u001B[0m, in \u001B[0;36mpreprocess_data\u001B[1;34m(data_frame)\u001B[0m\n\u001B[0;32m      8\u001B[0m data_frame\u001B[38;5;241m.\u001B[39mreplace([np\u001B[38;5;241m.\u001B[39minf, \u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39minf], np\u001B[38;5;241m.\u001B[39mnan, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;66;03m# Replace inf values with NaN\u001B[39;00m\n\u001B[0;32m      9\u001B[0m data_frame\u001B[38;5;241m.\u001B[39mdropna(inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;66;03m# Drop rows with NaN values\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m data_frame[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLabel\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdata_frame\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLabel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreprocess_label_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_frame\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLabel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data_frame\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4668\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4670\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1120\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_multiple()\n\u001B[0;32m   1118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m   1119\u001B[0m     \u001B[38;5;66;03m# if we are a string, try to dispatch\u001B[39;00m\n\u001B[1;32m-> 1120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1122\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_standard()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:580\u001B[0m, in \u001B[0;36mApply.apply_str\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    579\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOperation \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not support axis=1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 580\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_aggregate_string_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:662\u001B[0m, in \u001B[0;36mApply._try_aggregate_string_function\u001B[1;34m(self, obj, arg, *args, **kwargs)\u001B[0m\n\u001B[0;32m    658\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__array__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    659\u001B[0m     \u001B[38;5;66;03m# in particular exclude Window\u001B[39;00m\n\u001B[0;32m    660\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f(obj, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 662\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    663\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not a valid function for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(obj)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    664\u001B[0m )\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Benign' is not a valid function for 'Series' object"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using scikit-learn, train a decision tree classifier on the training set.\n",
    "Test the model firs with splitmode = 0.6 and then without splitmode.\n",
    "'''\n",
    "\n",
    "print(\"Creating train and test sets...\")\n",
    "train_data, test_data = get_dataset(path, splitmode=0.6)\n",
    "train_data.to_csv(\"train_data.csv\")\n",
    "test_data.to_csv(\"test_data.csv\")\n",
    "X_train, y_train = split_x_y(train_data)\n",
    "X_test, y_test = split_x_y(test_data)\n",
    "\n",
    "print(\"Training the decision tree classifier...\")\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "clf.predict(X_train)\n",
    "print(\"Accuracy on training set: \", clf.score(X_train, y_train))\n",
    "print(\"Accuracy on testing set: \", clf.score(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:09:18.076894100Z",
     "start_time": "2023-09-16T00:09:05.090732900Z"
    }
   },
   "id": "ae1e18e28ac5455"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
