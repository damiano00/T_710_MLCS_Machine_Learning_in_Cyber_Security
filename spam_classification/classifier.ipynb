{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T23:49:05.682450500Z",
     "start_time": "2023-08-29T23:49:05.682450500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T23:49:05.868539100Z",
     "start_time": "2023-08-29T23:49:05.682450500Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert all txt files into a single csv file\n",
    "corpus = './corpus.csv'\n",
    "test_corpus = './test_corpus.csv'\n",
    "train_path = './train-mails'\n",
    "test_path = './test-mails'\n",
    "with open(corpus, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['File Name', 'Content', 'Spam or Valid'])\n",
    "\n",
    "    for txt_filename in os.listdir(train_path):\n",
    "        if txt_filename.endswith('.txt'):\n",
    "            with open(os.path.join(train_path, txt_filename), 'r', encoding='utf-8') as txt_file:\n",
    "                content = txt_file.read()\n",
    "                spam_or_valid = 'spam' if txt_filename.startswith('spmsg') else 'valid'\n",
    "                csv_writer.writerow([txt_filename, content, spam_or_valid])\n",
    "\n",
    "with open(test_corpus, 'w', newline='', encoding='utf-8') as test_csv_file:\n",
    "    csv_writer = csv.writer(test_csv_file)\n",
    "    csv_writer.writerow(['File Name', 'Content', 'Spam or Valid'])\n",
    "\n",
    "    for txt_filename in os.listdir(test_path):\n",
    "        if txt_filename.endswith('.txt'):\n",
    "            with open(os.path.join(test_path, txt_filename), 'r', encoding='utf-8') as txt_file:\n",
    "                content = txt_file.read()\n",
    "                spam_or_valid = 'spam' if txt_filename.startswith('spmsg') else 'valid'\n",
    "                csv_writer.writerow([txt_filename, content, spam_or_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Create a dictionary of words (dropping all non-words like punctuation characters, single characters)\n",
    "# choosing the 2000 most frequent words from training set\n",
    "csv_file = pd.read_csv('./corpus.csv', encoding='utf-8')\n",
    "test_csv_file = pd.read_csv('./test_corpus.csv', encoding='utf-8')\n",
    "csv_file['Content'] = csv_file['Content'].str.replace(r'[^\\w\\s]+|(?<=\\s)\\S(?=\\s)|\\S(?<=\\s)','',regex=True)\n",
    "test_csv_file['Content'] = csv_file['Content'].str.replace(r'[^\\w\\s]+|(?<=\\s)\\S(?=\\s)|\\S(?<=\\s)','',regex=True)\n",
    "dictionary = {}\n",
    "for i in range(len(csv_file['Content'])):\n",
    "    for word in csv_file['Content'][i].split():\n",
    "        if word not in dictionary:\n",
    "            if len(word) > 1:\n",
    "                dictionary[word] = 1\n",
    "        elif word in dictionary:\n",
    "            dictionary[word] += 1\n",
    "    del dictionary['Subject']\n",
    "    \n",
    "\n",
    "top_2000_words = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)[:2000]\n",
    "sortedDictionary = dict(top_2000_words)\n",
    "#for word in top_2000_words:\n",
    "#   print(word) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T23:49:06.181350100Z",
     "start_time": "2023-08-29T23:49:05.868539100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-29T23:49:34.594133900Z",
     "start_time": "2023-08-29T23:49:06.190129500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimensions: 702 x 2000\n"
     ]
    }
   ],
   "source": [
    "# Transform each mail into a word count vector basing on the dictionary of words\n",
    "#word_count_matrix = CountVectorizer(vocabulary=sortedDictionary.keys()).transform(csv_file['Content'])\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for mail_index in range(len(csv_file['Content'])):\n",
    "    X_train.append([])\n",
    "    for key in sortedDictionary.keys():\n",
    "        word_counter = 0\n",
    "        for word in csv_file['Content'][mail_index].split():\n",
    "            if word == key:\n",
    "                word_counter += 1\n",
    "        X_train[-1].append(word_counter)\n",
    "    y_train.append(csv_file['Spam or Valid'][mail_index])\n",
    "\n",
    "for mail_index in range(len(test_csv_file['Content'])):\n",
    "    X_test.append([])\n",
    "    for key in sortedDictionary.keys():\n",
    "        word_counter = 0\n",
    "        for word in test_csv_file['Content'][mail_index].split():\n",
    "            if word == key:\n",
    "                word_counter += 1\n",
    "        X_test[-1].append(word_counter)\n",
    "    y_test.append(csv_file['Spam or Valid'][mail_index])\n",
    "\n",
    "print('Matrix dimensions:', len(X_train), 'x', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9858156028368794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        spam       0.98      0.98      0.98        54\n",
      "       valid       0.99      0.99      0.99        87\n",
      "\n",
      "    accuracy                           0.99       141\n",
      "   macro avg       0.98      0.98      0.98       141\n",
      "weighted avg       0.99      0.99      0.99       141\n"
     ]
    }
   ],
   "source": [
    "# Train a Bayes classifier (MultinomialNB from sklearn.naive_bayes)\n",
    "# Check with the test set the classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "print('Accuracy:', clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, clf.predict(X_test))    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T23:49:34.670903100Z",
     "start_time": "2023-08-29T23:49:34.594133900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
